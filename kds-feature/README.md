# KinesisÂ Local Benchmark (Rust â€‘ AWS SDK v1)

## 1Â Â·Â Purpose

Benchmark endâ€‘toâ€‘end latency when writing **1â€¯000** records to an AmazonÂ Kinesisâ€‘compatible endpoint (LocalStack) and consuming them concurrently with **4 parallel tasks**.

## 2Â Â·Â How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer   â”‚â”€1â€¯000â†’â”€â”€â–¶â”‚ 4Â Ã—Â KinesisÂ Shard â”‚â”€recordsâ”€â–¶â”‚ Consumer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   read   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Stream creation** â€“ The program ensures a stream called `test-stream` exists with `shard_count = 4`.
* **Produce phase** â€“ Sends 1â€¯000 individual `PutRecord` calls (`partition_key = pkâ€‘(0â€¥3)`), spreading load evenly across the 4 shards.
* **Consume phase** â€“ Spawns 4Â Tokio tasks (one per shard). Each task:

    1. Retrieves an iterator at `TrimHorizon`.
    2. Polls until the global counter reaches 1â€¯000.
* **Timing** â€“ A `std::time::Instant` marks the momentâ€¯all consumes start and stops once all tasks have finished.

## 3Â Â·Â Prerequisites

| Tool           | Version (tested)              |
| -------------- | ----------------------------- |
| Rust toolchain | 1.78.0â€‘stable                 |
| LocalStack     | 3.7+ (with `kinesis` service) |
| Docker         | 24.x                          |


### Expected console output (truncated)

```text
pk-3 â‡’ hello-0996
pk-0 â‡’ hello-0997
pk-1 â‡’ hello-0998
pk-2 â‡’ hello-0999
âœ… Read 1000 records in 240.847871ms
```

## 5Â Â·Â Tweaking the experiment

| Variable            | Location              | Description                                          |
| ------------------- | --------------------- | ---------------------------------------------------- |
| `TOTAL_RECORDS`     | `produce_records()`   | Change the number of events produced                 |
| `SHARD_COUNT`       | `ensure_stream_ready` | Scale shards up/down (and adjust consumer tasks)     |
| `worker_threads`    | `#[tokio::main]`      | Matches number of concurrent shard readers           |
| Sleep between polls | `consume_shard()`     | Tune `tokio::time::sleep(Duration::from_millis(20))` |

> \*\*TipÂ \*\*Â For higher throughput in real AWS, switch to `PutRecords` (batchÂ â‰¤Â 500) instead of individual calls.

## 6Â Â·Â Results &Â Interpretation

| Records | Shards | Runtime (ms) | Notes                                          |
| ------- | ------ | ------------ | ---------------------------------------------- |
| 1â€¯000   | 4      | â‰ˆâ€¯241Â ms     | Measured on M1Â ProÂ /Â macOS 14 / LocalStack 3.7 |

*LocalStack latency is dominated by Docker networking; real Kinesis usually adds â‰ˆÂ 10â€“20â€¯ms per hop but has stricter throughput limits.*

## 7Â Â·Â Next steps

* Benchmark `PutRecords` batches of varying sizes.
* Compare LocalStack vs. AWS usâ€‘eastâ€‘1.
* Experiment with larger shards (scaling via `UpdateShardCount`).
* Capture CloudWatch metrics when testing against AWS.

## 8Â Â·Â License

MITÂ â€”Â do whatever you want, but attribution is appreciated.

---

**Authored by:** Pablo &Â SkyÂ ğŸ¤
